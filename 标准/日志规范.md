### **Java 微服务日志规范**

为了提高日志的可读性、可追踪性、可监控性，并适应微服务架构下的分布式环境，制定以下日志规范：

------

## **1. 日志框架**

建议使用以下日志框架组合：

- **SLF4J + Logback**（推荐）
- **Spring Boot 默认使用 Logback**
- **支持 ELK（Elasticsearch + Logstash + Kibana）或 Loki + Promtail + Grafana 方案**

------

## **2. 日志级别（Log Level）**

使用 **TRACE < DEBUG < INFO < WARN < ERROR** 级别，分别适用于：

- **TRACE**（**追踪级**）—— 适用于详细方法调用、入参、返回值，仅用于本地调试。
- **DEBUG**（**调试级**）—— 适用于开发环境，记录重要变量、SQL等，不输出到生产环境。
- **INFO**（**信息级**）—— 适用于业务逻辑，如服务启动、接口调用成功、状态变更等。
- **WARN**（**警告级**）—— 适用于非致命异常、系统异常恢复等，如数据库连接断开但自动恢复。
- **ERROR**（**错误级**）—— 适用于影响功能的异常，如接口超时、数据库写入失败等。

✅ **推荐**：

- **生产环境默认级别：INFO**
- **调试环境可用：DEBUG**
- **ERROR 和 WARN 必须记录**

------

## **3. 日志格式规范**

**建议统一采用 JSON 格式**，便于 ELK/Grafana 解析。

### **3.1 标准日志格式**

```json
{
  "timestamp": "2025-02-10T12:34:56.789Z",
  "level": "INFO",
  "service": "user-service",
  "traceId": "abc123-xyz456",
  "spanId": "def789",
  "thread": "main",
  "logger": "com.example.UserController",
  "message": "User login success",
  "method": "POST",
  "uri": "/api/v1/login",
  "userId": 1001,
  "ip": "192.168.1.100",
  "elapsedTime": "150ms"
}
```

✅ **必要字段**：

- `timestamp`：日志时间（UTC格式）
- `level`：日志级别（INFO、WARN、ERROR等）
- `service`：微服务名称（如`order-service`）
- `traceId`：**分布式链路追踪ID**（用于请求全链路追踪）
- `spanId`：**链路追踪的子ID**
- `thread`：线程名称
- `logger`：日志所属类（如 `com.example.OrderService`）
- `message`：日志信息
- `method`：HTTP 方法（GET/POST）
- `uri`：请求 URI
- `userId`：用户 ID（可选）
- `ip`：用户 IP 地址
- `elapsedTime`：请求耗时（可选）

### **3.2 非 JSON 形式（适用于传统日志）**

```
2025-02-10 12:34:56.789 INFO  [user-service] [traceId=abc123-xyz456] [spanId=def789] [UserController] User login success
```

------

## **4. 日志存储与归档**

- 本地日志
  - 按 **日期+级别** 进行日志滚动，如 `logs/app-info-2025-02-10.log`
  - `INFO` 和 `ERROR` 应分开存储
- 日志保留周期
  - `DEBUG` 日志：保留 7 天
  - `INFO` 日志：保留 30 天
  - `ERROR` 日志：保留 90 天
- 日志输出
  - **开发环境**：`console + file`
  - **生产环境**：`file + ELK/Loki`
  - **错误日志建议上传到监控系统（如 ELK）**

------

## **5. 代码中的日志实践**

### **5.1 使用 SLF4J**

```java
private static final Logger log = LoggerFactory.getLogger(UserService.class);

public void login(String username) {
    log.info("User login attempt: {}", username);
}
```

✅ **避免字符串拼接**：

```java
// ❌ 不推荐（浪费性能）
log.info("User login attempt: " + username);

// ✅ 推荐（占位符格式化）
log.info("User login attempt: {}", username);
```

### **5.2 记录异常**

```java
try {
    int result = 10 / 0;
} catch (Exception e) {
    log.error("Division failed: {}", e.getMessage(), e);
}
```

------

## **6. 关键日志点**

✅ **在以下场景务必记录日志**：

1. 服务启动

   ：

   ```java
   log.info("Order service started successfully.");
   ```

2. 接口请求 & 响应

   ：

   ```java
   log.info("Request received: method=POST, uri=/orders, userId={}", userId);
   ```

3. 业务关键流程

   ：

   ```java
   log.info("Order placed: orderId={}, amount={}", orderId, amount);
   ```

4. 异常情况

   ：

   ```java
   log.error("Payment failed: orderId={}, error={}", orderId, e.getMessage(), e);
   ```

5. 外部系统交互

   ：

   ```java
   log.info("Calling payment service: requestId={}", requestId);
   ```

------

## **7. 链路追踪（Trace）**

✅ **Spring Cloud Sleuth + Zipkin/Jaeger**

- **所有日志应包含 `traceId`，确保全链路追踪**
- 结合 `MDC（Mapped Diagnostic Context）` 传递 `traceId`

```java
import org.slf4j.MDC;

MDC.put("traceId", UUID.randomUUID().toString());
log.info("Processing request...");
MDC.clear();
```

------

## **8. 监控 & 告警**

- 日志监控工具

  ：

  - **ELK**（Elasticsearch + Logstash + Kibana）
  - **Grafana + Loki**

- 异常日志告警

  ：

  - 关键错误日志需推送到 **钉钉、飞书、Prometheus AlertManager**
  - 规则：
    - `ERROR` 日志 10 分钟内超过 100 条 → 触发告警
    - 关键业务日志（如支付失败）异常率 > 5% → 触发告警

------

## **9. 日志最佳实践**

✅ **建议**

- 生产环境 **默认 INFO 级别**
- **避免 DEBUG 级日志污染生产日志**
- **避免记录敏感信息**（如密码、银行卡号）
- **使用 JSON 格式日志，方便 ELK 解析**
- **利用 traceId 进行全链路日志追踪**
- **定期清理日志，避免磁盘占满**

------

### **总结**

| 规范项         | 推荐做法                                                     |
| -------------- | ------------------------------------------------------------ |
| **日志级别**   | TRACE（调试）、DEBUG（开发）、INFO（生产）、WARN（警告）、ERROR（错误） |
| **日志格式**   | JSON 格式，包含 `traceId`、`service`、`uri`、`method`        |
| **存储方式**   | `console + file + ELK/Loki`，按天滚动                        |
| **关键日志点** | 服务启动、接口调用、业务核心逻辑、异常处理                   |
| **链路追踪**   | 使用 `traceId` 关联日志，支持 Zipkin/Jaeger                  |
| **异常处理**   | `log.error("xxx", e);` 避免 `e.printStackTrace()`            |
| **日志监控**   | ELK / Loki + Prometheus 进行监控和告警                       |

------

这样设计的日志规范既符合微服务架构特点，又能保证可观测性，满足实际业务需求。你觉得这些规范适合你的微服务环境吗？🚀