以下是Kafka消息队列的Topic和Consumer规范：

### **1. Topic 规范**

#### **1.1 命名规范**

- 业务前缀+描述性后缀

  ：格式为

  ```
  {业务模块}.{用途}
  ```

  ，例如：

  - `user.registration`（用户注册相关）
  - `order.payment`（订单支付相关）

- **避免使用大写字母**，Kafka的Topic名称通常使用小写字母和点（`.`）分隔。

- **避免特殊字符**，仅使用`a-z, 0-9, _ , .`。

#### **1.2 分区（Partition）**

- 分区数量

  ：根据业务需求合理设置，例如：

  - 低吞吐业务：`1-3`个分区
  - 中等吞吐业务：`3-10`个分区
  - 高吞吐业务：`10+`个分区

- **保持均衡负载**，确保生产者发送时使用合理的分区策略（如Key Hash）。

#### **1.3 副本（Replication）**

- **建议副本数：3**，保证高可用。
- **Leader均衡**，避免所有Leader集中在某个Broker上。

#### **1.4 过期与清理策略**

- **短生命周期数据**：`delete`策略，保留时间如`7天`或`1天`。
- **长生命周期数据**：`compact`策略，适用于日志压缩。

------

### **2. Consumer 规范**

#### **2.1 Consumer Group 规范**

- 同一业务组使用同一Group ID

  ，确保负载均衡，如：

  - `user_service_group`
  - `payment_service_group`

- **不同业务使用不同Group ID**，避免消息被错误消费。

#### **2.2 消费模式**

- **默认使用 `subscribe` 方式消费**，适用于大多数业务场景。
- **使用 `assign` 方式** 仅在手动分区管理的情况下，如数据迁移。

#### **2.3 Offset 提交方式**

- 自动提交（`enable.auto.commit=true`）

  ：

  - 适用于幂等消费、无严格消息顺序要求的场景。

- 手动提交（`enable.auto.commit=false`）

  ：

  - 适用于事务处理、精准消费的场景。

#### **2.4 幂等性 & 重试机制**

- **消费端实现幂等逻辑**，如基于`业务ID`去重。

- **合理设置 `max.poll.records`**，防止消息堆积，建议值如`100-500`。

- 异常消息处理

  ：

  - 短暂失败：`retry`（如重试3次）
  - 长时间失败：存入`DLQ`（死信队列）

------

### **3. 监控与运维**

- Kafka 监控

  ：

  - `kafka_exporter` + `Prometheus` + `Grafana` 监控消费速率、积压量。
  - `Kafka UI` 观察Topic消息状态。

- 消费异常告警

  ：

  - 消费滞后量超过`阈值X`时触发告警。
  - 长时间无消费时触发告警。

这个标准能满足你的Kafka管理需求吗？如果有具体业务需求，可以再细化。